{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tia3MP1SJpgj"
   },
   "source": [
    "# Springboard Data Science Career Track Unit 4 Challenge - Tier 3 Complete\n",
    "\n",
    "## Objectives\n",
    "Hey! Great job getting through those challenging DataCamp courses. You're learning a lot in a short span of time. \n",
    "\n",
    "In this notebook, you're going to apply the skills you've been learning, bridging the gap between the controlled environment of DataCamp and the *slightly* messier work that data scientists do with actual datasets!\n",
    "\n",
    "Here’s the mystery we’re going to solve: ***which boroughs of London have seen the greatest increase in housing prices, on average, over the last two decades?***\n",
    "\n",
    "\n",
    "A borough is just a fancy word for district. You may be familiar with the five boroughs of New York… well, there are 32 boroughs within Greater London [(here's some info for the curious)](https://en.wikipedia.org/wiki/London_boroughs). Some of them are more desirable areas to live in, and the data will reflect that with a greater rise in housing prices.\n",
    "\n",
    "***This is the Tier 3 notebook, which means it's not filled in at all: we'll just give you the skeleton of a project, the brief and the data. It's up to you to play around with it and see what you can find out! Good luck! If you struggle, feel free to look at easier tiers for help; but try to dip in and out of them, as the more independent work you do, the better it is for your learning!***\n",
    "\n",
    "This challenge will make use of only what you learned in the following DataCamp courses: \n",
    "- Prework courses (Introduction to Python for Data Science, Intermediate Python for Data Science)\n",
    "- Data Types for Data Science\n",
    "- Python Data Science Toolbox (Part One) \n",
    "- pandas Foundations\n",
    "- Manipulating DataFrames with pandas\n",
    "- Merging DataFrames with pandas\n",
    "\n",
    "Of the tools, techniques and concepts in the above DataCamp courses, this challenge should require the application of the following: \n",
    "- **pandas**\n",
    "    - **data ingestion and inspection** (pandas Foundations, Module One) \n",
    "    - **exploratory data analysis** (pandas Foundations, Module Two)\n",
    "    - **tidying and cleaning** (Manipulating DataFrames with pandas, Module Three) \n",
    "    - **transforming DataFrames** (Manipulating DataFrames with pandas, Module One)\n",
    "    - **subsetting DataFrames with lists** (Manipulating DataFrames with pandas, Module One) \n",
    "    - **filtering DataFrames** (Manipulating DataFrames with pandas, Module One) \n",
    "    - **grouping data** (Manipulating DataFrames with pandas, Module Four) \n",
    "    - **melting data** (Manipulating DataFrames with pandas, Module Three) \n",
    "    - **advanced indexing** (Manipulating DataFrames with pandas, Module Four) \n",
    "- **matplotlib** (Intermediate Python for Data Science, Module One)\n",
    "- **fundamental data types** (Data Types for Data Science, Module One) \n",
    "- **dictionaries** (Intermediate Python for Data Science, Module Two)\n",
    "- **handling dates and times** (Data Types for Data Science, Module Four)\n",
    "- **function definition** (Python Data Science Toolbox - Part One, Module One)\n",
    "- **default arguments, variable length, and scope** (Python Data Science Toolbox - Part One, Module Two) \n",
    "- **lambda functions and error handling** (Python Data Science Toolbox - Part One, Module Four) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ipgd2nV8Jpgl"
   },
   "source": [
    "## The Data Science Pipeline\n",
    "\n",
    "This is Tier Three, so we'll get you started. But after that, it's all in your hands! When you feel done with your investigations, look back over what you've accomplished, and prepare a quick presentation of your findings for the next mentor meeting. \n",
    "\n",
    "Data Science is magical. In this case study, you'll get to apply some complex machine learning algorithms. But as  [David Spiegelhalter](https://www.youtube.com/watch?v=oUs1uvsz0Ok) reminds us, there is no substitute for simply **taking a really, really good look at the data.** Sometimes, this is all we need to answer our question.\n",
    "\n",
    "Data Science projects generally adhere to the four stages of Data Science Pipeline:\n",
    "1. Sourcing and loading \n",
    "2. Cleaning, transforming, and visualizing \n",
    "3. Modeling \n",
    "4. Evaluating and concluding \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zswDqbefJpgm"
   },
   "source": [
    "### 1. Sourcing and Loading \n",
    "\n",
    "Any Data Science project kicks off by importing  ***pandas***. The documentation of this wonderful library can be found [here](https://pandas.pydata.org/). As you've seen, pandas is conveniently connected to the [Numpy](http://www.numpy.org/) and [Matplotlib](https://matplotlib.org/) libraries. \n",
    "\n",
    "***Hint:*** This part of the data science pipeline will test those skills you acquired in the pandas Foundations course, Module One. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEau5nEvJpgm"
   },
   "source": [
    "#### 1.1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Bt_Q_oPJpgn"
   },
   "outputs": [],
   "source": [
    "# Let's import the pandas, numpy libraries as pd, and np respectively. \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# Load the pyplot collection of functions from matplotlib, as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r\"D:\\IA\\SpringBoad\\DiegoRamos_Unit_4_Challenge_Tier_3\"\n",
    "os.chdir(save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "koUrawxsJpgq"
   },
   "source": [
    "#### 1.2.  Loading the data\n",
    "Your data comes from the [London Datastore](https://data.london.gov.uk/): a free, open-source data-sharing portal for London-oriented datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AiLiD4v3Jpgr",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City of London</th>\n",
       "      <th>Barking &amp; Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>Croydon</th>\n",
       "      <th>Ealing</th>\n",
       "      <th>Enfield</th>\n",
       "      <th>...</th>\n",
       "      <th>NORTH WEST</th>\n",
       "      <th>YORKS &amp; THE HUMBER</th>\n",
       "      <th>EAST MIDLANDS</th>\n",
       "      <th>WEST MIDLANDS</th>\n",
       "      <th>EAST OF ENGLAND</th>\n",
       "      <th>LONDON</th>\n",
       "      <th>SOUTH EAST</th>\n",
       "      <th>SOUTH WEST</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>England</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>E09000007</td>\n",
       "      <td>E09000008</td>\n",
       "      <td>E09000009</td>\n",
       "      <td>E09000010</td>\n",
       "      <td>...</td>\n",
       "      <td>E12000002</td>\n",
       "      <td>E12000003</td>\n",
       "      <td>E12000004</td>\n",
       "      <td>E12000005</td>\n",
       "      <td>E12000006</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>E12000008</td>\n",
       "      <td>E12000009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E92000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-01</th>\n",
       "      <td>91448.98487</td>\n",
       "      <td>50460.2266</td>\n",
       "      <td>93284.51832</td>\n",
       "      <td>64958.09036</td>\n",
       "      <td>71306.56698</td>\n",
       "      <td>81671.47692</td>\n",
       "      <td>120932.8881</td>\n",
       "      <td>69158.16225</td>\n",
       "      <td>79885.89069</td>\n",
       "      <td>72514.69096</td>\n",
       "      <td>...</td>\n",
       "      <td>43958.48001</td>\n",
       "      <td>44803.42878</td>\n",
       "      <td>45544.52227</td>\n",
       "      <td>48527.52339</td>\n",
       "      <td>56701.5961</td>\n",
       "      <td>74435.76052</td>\n",
       "      <td>64018.87894</td>\n",
       "      <td>54705.1579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53202.77128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-02-01</th>\n",
       "      <td>82202.77314</td>\n",
       "      <td>51085.77983</td>\n",
       "      <td>93190.16963</td>\n",
       "      <td>64787.92069</td>\n",
       "      <td>72022.26197</td>\n",
       "      <td>81657.55944</td>\n",
       "      <td>119508.8622</td>\n",
       "      <td>68951.09542</td>\n",
       "      <td>80897.06551</td>\n",
       "      <td>73155.19746</td>\n",
       "      <td>...</td>\n",
       "      <td>43925.42289</td>\n",
       "      <td>44528.80721</td>\n",
       "      <td>46051.57066</td>\n",
       "      <td>49341.29029</td>\n",
       "      <td>56593.59475</td>\n",
       "      <td>72777.93709</td>\n",
       "      <td>63715.02399</td>\n",
       "      <td>54356.14843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53096.1549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-03-01</th>\n",
       "      <td>79120.70256</td>\n",
       "      <td>51268.96956</td>\n",
       "      <td>92247.52435</td>\n",
       "      <td>64367.49344</td>\n",
       "      <td>72015.76274</td>\n",
       "      <td>81449.31143</td>\n",
       "      <td>120282.2131</td>\n",
       "      <td>68712.44341</td>\n",
       "      <td>81379.86288</td>\n",
       "      <td>72190.44144</td>\n",
       "      <td>...</td>\n",
       "      <td>44434.8681</td>\n",
       "      <td>45200.46775</td>\n",
       "      <td>45383.82395</td>\n",
       "      <td>49442.17973</td>\n",
       "      <td>56171.18278</td>\n",
       "      <td>73896.84204</td>\n",
       "      <td>64113.60858</td>\n",
       "      <td>53583.07667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53201.2843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-04-01</th>\n",
       "      <td>77101.20804</td>\n",
       "      <td>53133.50526</td>\n",
       "      <td>90762.87492</td>\n",
       "      <td>64277.66881</td>\n",
       "      <td>72965.63094</td>\n",
       "      <td>81124.41227</td>\n",
       "      <td>120097.899</td>\n",
       "      <td>68610.04641</td>\n",
       "      <td>82188.90498</td>\n",
       "      <td>71442.92235</td>\n",
       "      <td>...</td>\n",
       "      <td>44267.7796</td>\n",
       "      <td>45614.34341</td>\n",
       "      <td>46124.23045</td>\n",
       "      <td>49455.93299</td>\n",
       "      <td>56567.89582</td>\n",
       "      <td>74455.28754</td>\n",
       "      <td>64623.22395</td>\n",
       "      <td>54786.01938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53590.8548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-01</th>\n",
       "      <td>754954</td>\n",
       "      <td>340826</td>\n",
       "      <td>590027</td>\n",
       "      <td>401848</td>\n",
       "      <td>529279</td>\n",
       "      <td>498796</td>\n",
       "      <td>866645</td>\n",
       "      <td>390595</td>\n",
       "      <td>544636</td>\n",
       "      <td>440726</td>\n",
       "      <td>...</td>\n",
       "      <td>220357</td>\n",
       "      <td>212790</td>\n",
       "      <td>246475</td>\n",
       "      <td>253237</td>\n",
       "      <td>339438</td>\n",
       "      <td>525373</td>\n",
       "      <td>378821</td>\n",
       "      <td>317278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-01</th>\n",
       "      <td>750362</td>\n",
       "      <td>338083</td>\n",
       "      <td>596078</td>\n",
       "      <td>406623</td>\n",
       "      <td>545384</td>\n",
       "      <td>501619</td>\n",
       "      <td>859879</td>\n",
       "      <td>400992</td>\n",
       "      <td>552141</td>\n",
       "      <td>445600</td>\n",
       "      <td>...</td>\n",
       "      <td>224932</td>\n",
       "      <td>217597</td>\n",
       "      <td>249569</td>\n",
       "      <td>255449</td>\n",
       "      <td>344069</td>\n",
       "      <td>533030</td>\n",
       "      <td>385487</td>\n",
       "      <td>319006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-01</th>\n",
       "      <td>719570</td>\n",
       "      <td>340295</td>\n",
       "      <td>592861</td>\n",
       "      <td>408441</td>\n",
       "      <td>544571</td>\n",
       "      <td>505545</td>\n",
       "      <td>836335</td>\n",
       "      <td>403679</td>\n",
       "      <td>552791</td>\n",
       "      <td>452183</td>\n",
       "      <td>...</td>\n",
       "      <td>224679</td>\n",
       "      <td>215409</td>\n",
       "      <td>248137</td>\n",
       "      <td>256820</td>\n",
       "      <td>341833</td>\n",
       "      <td>527535</td>\n",
       "      <td>382266</td>\n",
       "      <td>320030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>308216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01</th>\n",
       "      <td>692265</td>\n",
       "      <td>340932</td>\n",
       "      <td>589938</td>\n",
       "      <td>408837</td>\n",
       "      <td>553641</td>\n",
       "      <td>504982</td>\n",
       "      <td>809041</td>\n",
       "      <td>406601</td>\n",
       "      <td>542144</td>\n",
       "      <td>449243</td>\n",
       "      <td>...</td>\n",
       "      <td>225229</td>\n",
       "      <td>216134</td>\n",
       "      <td>249674</td>\n",
       "      <td>254938</td>\n",
       "      <td>342956</td>\n",
       "      <td>516521</td>\n",
       "      <td>380455</td>\n",
       "      <td>323483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>670906</td>\n",
       "      <td>343528</td>\n",
       "      <td>592678</td>\n",
       "      <td>406441</td>\n",
       "      <td>545671</td>\n",
       "      <td>508954</td>\n",
       "      <td>815772</td>\n",
       "      <td>403054</td>\n",
       "      <td>541772</td>\n",
       "      <td>452341</td>\n",
       "      <td>...</td>\n",
       "      <td>226627</td>\n",
       "      <td>217939</td>\n",
       "      <td>248561</td>\n",
       "      <td>254912</td>\n",
       "      <td>339560</td>\n",
       "      <td>511279</td>\n",
       "      <td>377822</td>\n",
       "      <td>317608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           City of London Barking & Dagenham       Barnet       Bexley  \\\n",
       "NaT             E09000001          E09000002    E09000003    E09000004   \n",
       "1995-01-01    91448.98487         50460.2266  93284.51832  64958.09036   \n",
       "1995-02-01    82202.77314        51085.77983  93190.16963  64787.92069   \n",
       "1995-03-01    79120.70256        51268.96956  92247.52435  64367.49344   \n",
       "1995-04-01    77101.20804        53133.50526  90762.87492  64277.66881   \n",
       "...                   ...                ...          ...          ...   \n",
       "2024-07-01         754954             340826       590027       401848   \n",
       "2024-08-01         750362             338083       596078       406623   \n",
       "2024-09-01         719570             340295       592861       408441   \n",
       "2024-10-01         692265             340932       589938       408837   \n",
       "2024-11-01         670906             343528       592678       406441   \n",
       "\n",
       "                  Brent      Bromley       Camden      Croydon       Ealing  \\\n",
       "NaT           E09000005    E09000006    E09000007    E09000008    E09000009   \n",
       "1995-01-01  71306.56698  81671.47692  120932.8881  69158.16225  79885.89069   \n",
       "1995-02-01  72022.26197  81657.55944  119508.8622  68951.09542  80897.06551   \n",
       "1995-03-01  72015.76274  81449.31143  120282.2131  68712.44341  81379.86288   \n",
       "1995-04-01  72965.63094  81124.41227   120097.899  68610.04641  82188.90498   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "2024-07-01       529279       498796       866645       390595       544636   \n",
       "2024-08-01       545384       501619       859879       400992       552141   \n",
       "2024-09-01       544571       505545       836335       403679       552791   \n",
       "2024-10-01       553641       504982       809041       406601       542144   \n",
       "2024-11-01       545671       508954       815772       403054       541772   \n",
       "\n",
       "                Enfield  ...   NORTH WEST YORKS & THE HUMBER EAST MIDLANDS  \\\n",
       "NaT           E09000010  ...    E12000002          E12000003     E12000004   \n",
       "1995-01-01  72514.69096  ...  43958.48001        44803.42878   45544.52227   \n",
       "1995-02-01  73155.19746  ...  43925.42289        44528.80721   46051.57066   \n",
       "1995-03-01  72190.44144  ...   44434.8681        45200.46775   45383.82395   \n",
       "1995-04-01  71442.92235  ...   44267.7796        45614.34341   46124.23045   \n",
       "...                 ...  ...          ...                ...           ...   \n",
       "2024-07-01       440726  ...       220357             212790        246475   \n",
       "2024-08-01       445600  ...       224932             217597        249569   \n",
       "2024-09-01       452183  ...       224679             215409        248137   \n",
       "2024-10-01       449243  ...       225229             216134        249674   \n",
       "2024-11-01       452341  ...       226627             217939        248561   \n",
       "\n",
       "           WEST MIDLANDS EAST OF ENGLAND       LONDON   SOUTH EAST  \\\n",
       "NaT            E12000005       E12000006    E12000007    E12000008   \n",
       "1995-01-01   48527.52339      56701.5961  74435.76052  64018.87894   \n",
       "1995-02-01   49341.29029     56593.59475  72777.93709  63715.02399   \n",
       "1995-03-01   49442.17973     56171.18278  73896.84204  64113.60858   \n",
       "1995-04-01   49455.93299     56567.89582  74455.28754  64623.22395   \n",
       "...                  ...             ...          ...          ...   \n",
       "2024-07-01        253237          339438       525373       378821   \n",
       "2024-08-01        255449          344069       533030       385487   \n",
       "2024-09-01        256820          341833       527535       382266   \n",
       "2024-10-01        254938          342956       516521       380455   \n",
       "2024-11-01        254912          339560       511279       377822   \n",
       "\n",
       "             SOUTH WEST Unnamed: 47      England  \n",
       "NaT           E12000009         NaN    E92000001  \n",
       "1995-01-01   54705.1579         NaN  53202.77128  \n",
       "1995-02-01  54356.14843         NaN   53096.1549  \n",
       "1995-03-01  53583.07667         NaN   53201.2843  \n",
       "1995-04-01  54786.01938         NaN   53590.8548  \n",
       "...                 ...         ...          ...  \n",
       "2024-07-01       317278         NaN       304702  \n",
       "2024-08-01       319006         NaN       309170  \n",
       "2024-09-01       320030         NaN       308216  \n",
       "2024-10-01       323483         NaN       307665  \n",
       "2024-11-01       317608         NaN       306494  \n",
       "\n",
       "[360 rows x 48 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, make a variable called url_LondonHousePrices, and assign it the following link, enclosed in quotation-marks as a string:\n",
    "# https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\n",
    "\n",
    "url_LondonHousePrices = \"https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\"\n",
    "\n",
    "# The dataset we're interested in contains the Average prices of the houses, and is actually on a particular sheet of the Excel file. \n",
    "# As a result, we need to specify the sheet name in the read_excel() method.\n",
    "# Put this data into a variable called properties.  \n",
    "properties = pd.read_excel(url_LondonHousePrices, sheet_name='Average price', index_col= 0)\n",
    "properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 360 entries, NaT to 2024-11-01\n",
      "Data columns (total 48 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   City of London        360 non-null    object \n",
      " 1   Barking & Dagenham    360 non-null    object \n",
      " 2   Barnet                360 non-null    object \n",
      " 3   Bexley                360 non-null    object \n",
      " 4   Brent                 360 non-null    object \n",
      " 5   Bromley               360 non-null    object \n",
      " 6   Camden                360 non-null    object \n",
      " 7   Croydon               360 non-null    object \n",
      " 8   Ealing                360 non-null    object \n",
      " 9   Enfield               360 non-null    object \n",
      " 10  Greenwich             360 non-null    object \n",
      " 11  Hackney               360 non-null    object \n",
      " 12  Hammersmith & Fulham  360 non-null    object \n",
      " 13  Haringey              360 non-null    object \n",
      " 14  Harrow                360 non-null    object \n",
      " 15  Havering              360 non-null    object \n",
      " 16  Hillingdon            360 non-null    object \n",
      " 17  Hounslow              360 non-null    object \n",
      " 18  Islington             360 non-null    object \n",
      " 19  Kensington & Chelsea  360 non-null    object \n",
      " 20  Kingston upon Thames  360 non-null    object \n",
      " 21  Lambeth               360 non-null    object \n",
      " 22  Lewisham              360 non-null    object \n",
      " 23  Merton                360 non-null    object \n",
      " 24  Newham                360 non-null    object \n",
      " 25  Redbridge             360 non-null    object \n",
      " 26  Richmond upon Thames  360 non-null    object \n",
      " 27  Southwark             360 non-null    object \n",
      " 28  Sutton                360 non-null    object \n",
      " 29  Tower Hamlets         360 non-null    object \n",
      " 30  Waltham Forest        360 non-null    object \n",
      " 31  Wandsworth            360 non-null    object \n",
      " 32  Westminster           360 non-null    object \n",
      " 33  Unnamed: 34           0 non-null      float64\n",
      " 34  Inner London          360 non-null    object \n",
      " 35  Outer London          360 non-null    object \n",
      " 36  Unnamed: 37           0 non-null      float64\n",
      " 37  NORTH EAST            360 non-null    object \n",
      " 38  NORTH WEST            360 non-null    object \n",
      " 39  YORKS & THE HUMBER    360 non-null    object \n",
      " 40  EAST MIDLANDS         360 non-null    object \n",
      " 41  WEST MIDLANDS         360 non-null    object \n",
      " 42  EAST OF ENGLAND       360 non-null    object \n",
      " 43  LONDON                360 non-null    object \n",
      " 44  SOUTH EAST            360 non-null    object \n",
      " 45  SOUTH WEST            360 non-null    object \n",
      " 46  Unnamed: 47           0 non-null      float64\n",
      " 47  England               360 non-null    object \n",
      "dtypes: float64(3), object(45)\n",
      "memory usage: 137.8+ KB\n"
     ]
    }
   ],
   "source": [
    "properties.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "POukEJXgJpgu"
   },
   "source": [
    "### 2. Cleaning, transforming, and visualizing\n",
    "This second stage is arguably the most important part of any Data Science project. The first thing to do is take a proper look at the data. Cleaning forms the majority of this stage, and can be done both before or after Transformation.\n",
    "\n",
    "The end goal of data cleaning is to have tidy data. When data is tidy: \n",
    "\n",
    "1. Each variable has a column.\n",
    "2. Each observation forms a row.\n",
    "\n",
    "Keep the end goal in mind as you move through this process, every step will take you closer. \n",
    "\n",
    "\n",
    "\n",
    "***Hint:*** This part of the data science pipeline should test those skills you acquired in: \n",
    "- Intermediate Python for data science, all modules.\n",
    "- pandas Foundations, all modules. \n",
    "- Manipulating DataFrames with pandas, all modules.\n",
    "- Data Types for Data Science, Module Four.\n",
    "- Python Data Science Toolbox - Part One, all modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Te0Q548tnzZa"
   },
   "source": [
    "**2.1. Exploring your data** \n",
    "\n",
    "Think about your pandas functions for checking out a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rxirxw_qoAJa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City of London</th>\n",
       "      <th>Barking &amp; Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>Croydon</th>\n",
       "      <th>Ealing</th>\n",
       "      <th>Enfield</th>\n",
       "      <th>...</th>\n",
       "      <th>NORTH WEST</th>\n",
       "      <th>YORKS &amp; THE HUMBER</th>\n",
       "      <th>EAST MIDLANDS</th>\n",
       "      <th>WEST MIDLANDS</th>\n",
       "      <th>EAST OF ENGLAND</th>\n",
       "      <th>LONDON</th>\n",
       "      <th>SOUTH EAST</th>\n",
       "      <th>SOUTH WEST</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>England</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>E09000007</td>\n",
       "      <td>E09000008</td>\n",
       "      <td>E09000009</td>\n",
       "      <td>E09000010</td>\n",
       "      <td>...</td>\n",
       "      <td>E12000002</td>\n",
       "      <td>E12000003</td>\n",
       "      <td>E12000004</td>\n",
       "      <td>E12000005</td>\n",
       "      <td>E12000006</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>E12000008</td>\n",
       "      <td>E12000009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E92000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-01</th>\n",
       "      <td>91448.98487</td>\n",
       "      <td>50460.2266</td>\n",
       "      <td>93284.51832</td>\n",
       "      <td>64958.09036</td>\n",
       "      <td>71306.56698</td>\n",
       "      <td>81671.47692</td>\n",
       "      <td>120932.8881</td>\n",
       "      <td>69158.16225</td>\n",
       "      <td>79885.89069</td>\n",
       "      <td>72514.69096</td>\n",
       "      <td>...</td>\n",
       "      <td>43958.48001</td>\n",
       "      <td>44803.42878</td>\n",
       "      <td>45544.52227</td>\n",
       "      <td>48527.52339</td>\n",
       "      <td>56701.5961</td>\n",
       "      <td>74435.76052</td>\n",
       "      <td>64018.87894</td>\n",
       "      <td>54705.1579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53202.77128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-02-01</th>\n",
       "      <td>82202.77314</td>\n",
       "      <td>51085.77983</td>\n",
       "      <td>93190.16963</td>\n",
       "      <td>64787.92069</td>\n",
       "      <td>72022.26197</td>\n",
       "      <td>81657.55944</td>\n",
       "      <td>119508.8622</td>\n",
       "      <td>68951.09542</td>\n",
       "      <td>80897.06551</td>\n",
       "      <td>73155.19746</td>\n",
       "      <td>...</td>\n",
       "      <td>43925.42289</td>\n",
       "      <td>44528.80721</td>\n",
       "      <td>46051.57066</td>\n",
       "      <td>49341.29029</td>\n",
       "      <td>56593.59475</td>\n",
       "      <td>72777.93709</td>\n",
       "      <td>63715.02399</td>\n",
       "      <td>54356.14843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53096.1549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-03-01</th>\n",
       "      <td>79120.70256</td>\n",
       "      <td>51268.96956</td>\n",
       "      <td>92247.52435</td>\n",
       "      <td>64367.49344</td>\n",
       "      <td>72015.76274</td>\n",
       "      <td>81449.31143</td>\n",
       "      <td>120282.2131</td>\n",
       "      <td>68712.44341</td>\n",
       "      <td>81379.86288</td>\n",
       "      <td>72190.44144</td>\n",
       "      <td>...</td>\n",
       "      <td>44434.8681</td>\n",
       "      <td>45200.46775</td>\n",
       "      <td>45383.82395</td>\n",
       "      <td>49442.17973</td>\n",
       "      <td>56171.18278</td>\n",
       "      <td>73896.84204</td>\n",
       "      <td>64113.60858</td>\n",
       "      <td>53583.07667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53201.2843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-04-01</th>\n",
       "      <td>77101.20804</td>\n",
       "      <td>53133.50526</td>\n",
       "      <td>90762.87492</td>\n",
       "      <td>64277.66881</td>\n",
       "      <td>72965.63094</td>\n",
       "      <td>81124.41227</td>\n",
       "      <td>120097.899</td>\n",
       "      <td>68610.04641</td>\n",
       "      <td>82188.90498</td>\n",
       "      <td>71442.92235</td>\n",
       "      <td>...</td>\n",
       "      <td>44267.7796</td>\n",
       "      <td>45614.34341</td>\n",
       "      <td>46124.23045</td>\n",
       "      <td>49455.93299</td>\n",
       "      <td>56567.89582</td>\n",
       "      <td>74455.28754</td>\n",
       "      <td>64623.22395</td>\n",
       "      <td>54786.01938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53590.8548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           City of London Barking & Dagenham       Barnet       Bexley  \\\n",
       "NaT             E09000001          E09000002    E09000003    E09000004   \n",
       "1995-01-01    91448.98487         50460.2266  93284.51832  64958.09036   \n",
       "1995-02-01    82202.77314        51085.77983  93190.16963  64787.92069   \n",
       "1995-03-01    79120.70256        51268.96956  92247.52435  64367.49344   \n",
       "1995-04-01    77101.20804        53133.50526  90762.87492  64277.66881   \n",
       "\n",
       "                  Brent      Bromley       Camden      Croydon       Ealing  \\\n",
       "NaT           E09000005    E09000006    E09000007    E09000008    E09000009   \n",
       "1995-01-01  71306.56698  81671.47692  120932.8881  69158.16225  79885.89069   \n",
       "1995-02-01  72022.26197  81657.55944  119508.8622  68951.09542  80897.06551   \n",
       "1995-03-01  72015.76274  81449.31143  120282.2131  68712.44341  81379.86288   \n",
       "1995-04-01  72965.63094  81124.41227   120097.899  68610.04641  82188.90498   \n",
       "\n",
       "                Enfield  ...   NORTH WEST YORKS & THE HUMBER EAST MIDLANDS  \\\n",
       "NaT           E09000010  ...    E12000002          E12000003     E12000004   \n",
       "1995-01-01  72514.69096  ...  43958.48001        44803.42878   45544.52227   \n",
       "1995-02-01  73155.19746  ...  43925.42289        44528.80721   46051.57066   \n",
       "1995-03-01  72190.44144  ...   44434.8681        45200.46775   45383.82395   \n",
       "1995-04-01  71442.92235  ...   44267.7796        45614.34341   46124.23045   \n",
       "\n",
       "           WEST MIDLANDS EAST OF ENGLAND       LONDON   SOUTH EAST  \\\n",
       "NaT            E12000005       E12000006    E12000007    E12000008   \n",
       "1995-01-01   48527.52339      56701.5961  74435.76052  64018.87894   \n",
       "1995-02-01   49341.29029     56593.59475  72777.93709  63715.02399   \n",
       "1995-03-01   49442.17973     56171.18278  73896.84204  64113.60858   \n",
       "1995-04-01   49455.93299     56567.89582  74455.28754  64623.22395   \n",
       "\n",
       "             SOUTH WEST Unnamed: 47      England  \n",
       "NaT           E12000009         NaN    E92000001  \n",
       "1995-01-01   54705.1579         NaN  53202.77128  \n",
       "1995-02-01  54356.14843         NaN   53096.1549  \n",
       "1995-03-01  53583.07667         NaN   53201.2843  \n",
       "1995-04-01  54786.01938         NaN   53590.8548  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tE9Sqt9-oAta"
   },
   "source": [
    "**2.2. Cleaning the data**\n",
    "\n",
    "You might find you need to transpose your dataframe, check out what its row indexes are, and reset the index. You  also might find you need to assign the values of the first row to your column headings  . (Hint: recall the .columns feature of DataFrames, as well as the iloc[] method).\n",
    "\n",
    "Don't be afraid to use StackOverflow for help  with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdAu1A3YoH_r"
   },
   "outputs": [],
   "source": [
    "# dataframe feature engineering\n",
    "\n",
    "properties.drop(index=pd.NaT, inplace=True, errors='ignore')\n",
    "properties.drop(columns=[col for col in properties.columns if col.startswith(\"Unnamed\")], inplace=True)\n",
    "properties.columns = properties.columns.str.lower().str.capitalize()\n",
    "properties.reset_index(inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o1uLbJAsoIjK"
   },
   "source": [
    "**2.3. Cleaning the data (part 2)**\n",
    "\n",
    "You might we have to **rename** a couple columns. How do you do this? The clue's pretty bold..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKkmn1AnoVZS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>City of london</th>\n",
       "      <th>Barking &amp; dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>Croydon</th>\n",
       "      <th>Ealing</th>\n",
       "      <th>...</th>\n",
       "      <th>North east</th>\n",
       "      <th>North west</th>\n",
       "      <th>Yorks &amp; the humber</th>\n",
       "      <th>East midlands</th>\n",
       "      <th>West midlands</th>\n",
       "      <th>East of england</th>\n",
       "      <th>London</th>\n",
       "      <th>South east</th>\n",
       "      <th>South west</th>\n",
       "      <th>England</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>91448.98487</td>\n",
       "      <td>50460.2266</td>\n",
       "      <td>93284.51832</td>\n",
       "      <td>64958.09036</td>\n",
       "      <td>71306.56698</td>\n",
       "      <td>81671.47692</td>\n",
       "      <td>120932.8881</td>\n",
       "      <td>69158.16225</td>\n",
       "      <td>79885.89069</td>\n",
       "      <td>...</td>\n",
       "      <td>42076.35411</td>\n",
       "      <td>43958.48001</td>\n",
       "      <td>44803.42878</td>\n",
       "      <td>45544.52227</td>\n",
       "      <td>48527.52339</td>\n",
       "      <td>56701.5961</td>\n",
       "      <td>74435.76052</td>\n",
       "      <td>64018.87894</td>\n",
       "      <td>54705.1579</td>\n",
       "      <td>53202.77128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>82202.77314</td>\n",
       "      <td>51085.77983</td>\n",
       "      <td>93190.16963</td>\n",
       "      <td>64787.92069</td>\n",
       "      <td>72022.26197</td>\n",
       "      <td>81657.55944</td>\n",
       "      <td>119508.8622</td>\n",
       "      <td>68951.09542</td>\n",
       "      <td>80897.06551</td>\n",
       "      <td>...</td>\n",
       "      <td>42571.98949</td>\n",
       "      <td>43925.42289</td>\n",
       "      <td>44528.80721</td>\n",
       "      <td>46051.57066</td>\n",
       "      <td>49341.29029</td>\n",
       "      <td>56593.59475</td>\n",
       "      <td>72777.93709</td>\n",
       "      <td>63715.02399</td>\n",
       "      <td>54356.14843</td>\n",
       "      <td>53096.1549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995-03-01</td>\n",
       "      <td>79120.70256</td>\n",
       "      <td>51268.96956</td>\n",
       "      <td>92247.52435</td>\n",
       "      <td>64367.49344</td>\n",
       "      <td>72015.76274</td>\n",
       "      <td>81449.31143</td>\n",
       "      <td>120282.2131</td>\n",
       "      <td>68712.44341</td>\n",
       "      <td>81379.86288</td>\n",
       "      <td>...</td>\n",
       "      <td>42369.72984</td>\n",
       "      <td>44434.8681</td>\n",
       "      <td>45200.46775</td>\n",
       "      <td>45383.82395</td>\n",
       "      <td>49442.17973</td>\n",
       "      <td>56171.18278</td>\n",
       "      <td>73896.84204</td>\n",
       "      <td>64113.60858</td>\n",
       "      <td>53583.07667</td>\n",
       "      <td>53201.2843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995-04-01</td>\n",
       "      <td>77101.20804</td>\n",
       "      <td>53133.50526</td>\n",
       "      <td>90762.87492</td>\n",
       "      <td>64277.66881</td>\n",
       "      <td>72965.63094</td>\n",
       "      <td>81124.41227</td>\n",
       "      <td>120097.899</td>\n",
       "      <td>68610.04641</td>\n",
       "      <td>82188.90498</td>\n",
       "      <td>...</td>\n",
       "      <td>42095.8436</td>\n",
       "      <td>44267.7796</td>\n",
       "      <td>45614.34341</td>\n",
       "      <td>46124.23045</td>\n",
       "      <td>49455.93299</td>\n",
       "      <td>56567.89582</td>\n",
       "      <td>74455.28754</td>\n",
       "      <td>64623.22395</td>\n",
       "      <td>54786.01938</td>\n",
       "      <td>53590.8548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995-05-01</td>\n",
       "      <td>84409.14932</td>\n",
       "      <td>53042.24852</td>\n",
       "      <td>90258.00033</td>\n",
       "      <td>63997.13588</td>\n",
       "      <td>73704.04743</td>\n",
       "      <td>81542.61561</td>\n",
       "      <td>119929.2782</td>\n",
       "      <td>68844.9169</td>\n",
       "      <td>82077.05525</td>\n",
       "      <td>...</td>\n",
       "      <td>43266.45165</td>\n",
       "      <td>44223.61973</td>\n",
       "      <td>44830.98563</td>\n",
       "      <td>45878.00396</td>\n",
       "      <td>50369.66188</td>\n",
       "      <td>56479.80183</td>\n",
       "      <td>75432.02786</td>\n",
       "      <td>64530.36358</td>\n",
       "      <td>54698.83831</td>\n",
       "      <td>53678.24041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date City of london Barking & dagenham       Barnet       Bexley  \\\n",
       "0  1995-01-01    91448.98487         50460.2266  93284.51832  64958.09036   \n",
       "1  1995-02-01    82202.77314        51085.77983  93190.16963  64787.92069   \n",
       "2  1995-03-01    79120.70256        51268.96956  92247.52435  64367.49344   \n",
       "3  1995-04-01    77101.20804        53133.50526  90762.87492  64277.66881   \n",
       "4  1995-05-01    84409.14932        53042.24852  90258.00033  63997.13588   \n",
       "\n",
       "         Brent      Bromley       Camden      Croydon       Ealing  ...  \\\n",
       "0  71306.56698  81671.47692  120932.8881  69158.16225  79885.89069  ...   \n",
       "1  72022.26197  81657.55944  119508.8622  68951.09542  80897.06551  ...   \n",
       "2  72015.76274  81449.31143  120282.2131  68712.44341  81379.86288  ...   \n",
       "3  72965.63094  81124.41227   120097.899  68610.04641  82188.90498  ...   \n",
       "4  73704.04743  81542.61561  119929.2782   68844.9169  82077.05525  ...   \n",
       "\n",
       "    North east   North west Yorks & the humber East midlands West midlands  \\\n",
       "0  42076.35411  43958.48001        44803.42878   45544.52227   48527.52339   \n",
       "1  42571.98949  43925.42289        44528.80721   46051.57066   49341.29029   \n",
       "2  42369.72984   44434.8681        45200.46775   45383.82395   49442.17973   \n",
       "3   42095.8436   44267.7796        45614.34341   46124.23045   49455.93299   \n",
       "4  43266.45165  44223.61973        44830.98563   45878.00396   50369.66188   \n",
       "\n",
       "  East of england       London   South east   South west      England  \n",
       "0      56701.5961  74435.76052  64018.87894   54705.1579  53202.77128  \n",
       "1     56593.59475  72777.93709  63715.02399  54356.14843   53096.1549  \n",
       "2     56171.18278  73896.84204  64113.60858  53583.07667   53201.2843  \n",
       "3     56567.89582  74455.28754  64623.22395  54786.01938   53590.8548  \n",
       "4     56479.80183  75432.02786  64530.36358  54698.83831  53678.24041  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename column and date time format\n",
    "\n",
    "properties.rename(columns = {'index':'Date'}, inplace = True)\n",
    "properties['Date'] = pd.to_datetime(properties['Date'], format = '%Y-%m-%d').dt.date\n",
    "\n",
    "\n",
    "properties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jy8BzXHmoWEw"
   },
   "source": [
    "**2.4.Transforming the data**\n",
    "\n",
    "Remember what Wes McKinney said about tidy data? \n",
    "\n",
    "You might need to **melt** your DataFrame here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2wM0qLuo2Zt",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>349</th>\n",
       "      <th>350</th>\n",
       "      <th>351</th>\n",
       "      <th>352</th>\n",
       "      <th>353</th>\n",
       "      <th>354</th>\n",
       "      <th>355</th>\n",
       "      <th>356</th>\n",
       "      <th>357</th>\n",
       "      <th>358</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>1995-03-01</td>\n",
       "      <td>1995-04-01</td>\n",
       "      <td>1995-05-01</td>\n",
       "      <td>1995-06-01</td>\n",
       "      <td>1995-07-01</td>\n",
       "      <td>1995-08-01</td>\n",
       "      <td>1995-09-01</td>\n",
       "      <td>1995-10-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>2024-08-01</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>2024-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of london</th>\n",
       "      <td>91448.98487</td>\n",
       "      <td>82202.77314</td>\n",
       "      <td>79120.70256</td>\n",
       "      <td>77101.20804</td>\n",
       "      <td>84409.14932</td>\n",
       "      <td>94900.51244</td>\n",
       "      <td>110128.0423</td>\n",
       "      <td>112329.4376</td>\n",
       "      <td>104473.1096</td>\n",
       "      <td>108038.1181</td>\n",
       "      <td>...</td>\n",
       "      <td>840075</td>\n",
       "      <td>831249</td>\n",
       "      <td>810250</td>\n",
       "      <td>813219</td>\n",
       "      <td>808227</td>\n",
       "      <td>754954</td>\n",
       "      <td>750362</td>\n",
       "      <td>719570</td>\n",
       "      <td>692265</td>\n",
       "      <td>670906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barking &amp; dagenham</th>\n",
       "      <td>50460.2266</td>\n",
       "      <td>51085.77983</td>\n",
       "      <td>51268.96956</td>\n",
       "      <td>53133.50526</td>\n",
       "      <td>53042.24852</td>\n",
       "      <td>53700.34831</td>\n",
       "      <td>52113.12157</td>\n",
       "      <td>52232.19868</td>\n",
       "      <td>51471.61353</td>\n",
       "      <td>51513.7576</td>\n",
       "      <td>...</td>\n",
       "      <td>328266</td>\n",
       "      <td>333303</td>\n",
       "      <td>335559</td>\n",
       "      <td>335794</td>\n",
       "      <td>332826</td>\n",
       "      <td>340826</td>\n",
       "      <td>338083</td>\n",
       "      <td>340295</td>\n",
       "      <td>340932</td>\n",
       "      <td>343528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barnet</th>\n",
       "      <td>93284.51832</td>\n",
       "      <td>93190.16963</td>\n",
       "      <td>92247.52435</td>\n",
       "      <td>90762.87492</td>\n",
       "      <td>90258.00033</td>\n",
       "      <td>90107.23471</td>\n",
       "      <td>91441.24768</td>\n",
       "      <td>92361.31512</td>\n",
       "      <td>93273.12245</td>\n",
       "      <td>92567.38498</td>\n",
       "      <td>...</td>\n",
       "      <td>563115</td>\n",
       "      <td>569976</td>\n",
       "      <td>573051</td>\n",
       "      <td>580130</td>\n",
       "      <td>584621</td>\n",
       "      <td>590027</td>\n",
       "      <td>596078</td>\n",
       "      <td>592861</td>\n",
       "      <td>589938</td>\n",
       "      <td>592678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bexley</th>\n",
       "      <td>64958.09036</td>\n",
       "      <td>64787.92069</td>\n",
       "      <td>64367.49344</td>\n",
       "      <td>64277.66881</td>\n",
       "      <td>63997.13588</td>\n",
       "      <td>64252.32335</td>\n",
       "      <td>63722.70055</td>\n",
       "      <td>64432.60005</td>\n",
       "      <td>64509.54767</td>\n",
       "      <td>64529.93725</td>\n",
       "      <td>...</td>\n",
       "      <td>394741</td>\n",
       "      <td>395633</td>\n",
       "      <td>396584</td>\n",
       "      <td>396070</td>\n",
       "      <td>400617</td>\n",
       "      <td>401848</td>\n",
       "      <td>406623</td>\n",
       "      <td>408441</td>\n",
       "      <td>408837</td>\n",
       "      <td>406441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 359 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0            1            2            3    \\\n",
       "Date                 1995-01-01   1995-02-01   1995-03-01   1995-04-01   \n",
       "City of london      91448.98487  82202.77314  79120.70256  77101.20804   \n",
       "Barking & dagenham   50460.2266  51085.77983  51268.96956  53133.50526   \n",
       "Barnet              93284.51832  93190.16963  92247.52435  90762.87492   \n",
       "Bexley              64958.09036  64787.92069  64367.49344  64277.66881   \n",
       "\n",
       "                            4            5            6            7    \\\n",
       "Date                 1995-05-01   1995-06-01   1995-07-01   1995-08-01   \n",
       "City of london      84409.14932  94900.51244  110128.0423  112329.4376   \n",
       "Barking & dagenham  53042.24852  53700.34831  52113.12157  52232.19868   \n",
       "Barnet              90258.00033  90107.23471  91441.24768  92361.31512   \n",
       "Bexley              63997.13588  64252.32335  63722.70055  64432.60005   \n",
       "\n",
       "                            8            9    ...         349         350  \\\n",
       "Date                 1995-09-01   1995-10-01  ...  2024-02-01  2024-03-01   \n",
       "City of london      104473.1096  108038.1181  ...      840075      831249   \n",
       "Barking & dagenham  51471.61353   51513.7576  ...      328266      333303   \n",
       "Barnet              93273.12245  92567.38498  ...      563115      569976   \n",
       "Bexley              64509.54767  64529.93725  ...      394741      395633   \n",
       "\n",
       "                           351         352         353         354  \\\n",
       "Date                2024-04-01  2024-05-01  2024-06-01  2024-07-01   \n",
       "City of london          810250      813219      808227      754954   \n",
       "Barking & dagenham      335559      335794      332826      340826   \n",
       "Barnet                  573051      580130      584621      590027   \n",
       "Bexley                  396584      396070      400617      401848   \n",
       "\n",
       "                           355         356         357         358  \n",
       "Date                2024-08-01  2024-09-01  2024-10-01  2024-11-01  \n",
       "City of london          750362      719570      692265      670906  \n",
       "Barking & dagenham      338083      340295      340932      343528  \n",
       "Barnet                  596078      592861      589938      592678  \n",
       "Bexley                  406623      408441      408837      406441  \n",
       "\n",
       "[5 rows x 359 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transpose data\n",
    "\n",
    "properties = np.transpose(properties)\n",
    "\n",
    "properties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7kIsgAo7o3mf"
   },
   "source": [
    "Remember to make sure your column data types are all correct. Average prices, for example, should be floating point numbers... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZcR4IHbcpOaq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>349</th>\n",
       "      <th>350</th>\n",
       "      <th>351</th>\n",
       "      <th>352</th>\n",
       "      <th>353</th>\n",
       "      <th>354</th>\n",
       "      <th>355</th>\n",
       "      <th>356</th>\n",
       "      <th>357</th>\n",
       "      <th>358</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>1995-03-01</td>\n",
       "      <td>1995-04-01</td>\n",
       "      <td>1995-05-01</td>\n",
       "      <td>1995-06-01</td>\n",
       "      <td>1995-07-01</td>\n",
       "      <td>1995-08-01</td>\n",
       "      <td>1995-09-01</td>\n",
       "      <td>1995-10-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>2024-08-01</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>2024-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of london</th>\n",
       "      <td>91448.985</td>\n",
       "      <td>82202.773</td>\n",
       "      <td>79120.703</td>\n",
       "      <td>77101.208</td>\n",
       "      <td>84409.149</td>\n",
       "      <td>94900.512</td>\n",
       "      <td>110128.042</td>\n",
       "      <td>112329.438</td>\n",
       "      <td>104473.11</td>\n",
       "      <td>108038.118</td>\n",
       "      <td>...</td>\n",
       "      <td>840075.0</td>\n",
       "      <td>831249.0</td>\n",
       "      <td>810250.0</td>\n",
       "      <td>813219.0</td>\n",
       "      <td>808227.0</td>\n",
       "      <td>754954.0</td>\n",
       "      <td>750362.0</td>\n",
       "      <td>719570.0</td>\n",
       "      <td>692265.0</td>\n",
       "      <td>670906.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barking &amp; dagenham</th>\n",
       "      <td>50460.227</td>\n",
       "      <td>51085.78</td>\n",
       "      <td>51268.97</td>\n",
       "      <td>53133.505</td>\n",
       "      <td>53042.249</td>\n",
       "      <td>53700.348</td>\n",
       "      <td>52113.122</td>\n",
       "      <td>52232.199</td>\n",
       "      <td>51471.614</td>\n",
       "      <td>51513.758</td>\n",
       "      <td>...</td>\n",
       "      <td>328266.0</td>\n",
       "      <td>333303.0</td>\n",
       "      <td>335559.0</td>\n",
       "      <td>335794.0</td>\n",
       "      <td>332826.0</td>\n",
       "      <td>340826.0</td>\n",
       "      <td>338083.0</td>\n",
       "      <td>340295.0</td>\n",
       "      <td>340932.0</td>\n",
       "      <td>343528.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barnet</th>\n",
       "      <td>93284.518</td>\n",
       "      <td>93190.17</td>\n",
       "      <td>92247.524</td>\n",
       "      <td>90762.875</td>\n",
       "      <td>90258.0</td>\n",
       "      <td>90107.235</td>\n",
       "      <td>91441.248</td>\n",
       "      <td>92361.315</td>\n",
       "      <td>93273.122</td>\n",
       "      <td>92567.385</td>\n",
       "      <td>...</td>\n",
       "      <td>563115.0</td>\n",
       "      <td>569976.0</td>\n",
       "      <td>573051.0</td>\n",
       "      <td>580130.0</td>\n",
       "      <td>584621.0</td>\n",
       "      <td>590027.0</td>\n",
       "      <td>596078.0</td>\n",
       "      <td>592861.0</td>\n",
       "      <td>589938.0</td>\n",
       "      <td>592678.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bexley</th>\n",
       "      <td>64958.09</td>\n",
       "      <td>64787.921</td>\n",
       "      <td>64367.493</td>\n",
       "      <td>64277.669</td>\n",
       "      <td>63997.136</td>\n",
       "      <td>64252.323</td>\n",
       "      <td>63722.701</td>\n",
       "      <td>64432.6</td>\n",
       "      <td>64509.548</td>\n",
       "      <td>64529.937</td>\n",
       "      <td>...</td>\n",
       "      <td>394741.0</td>\n",
       "      <td>395633.0</td>\n",
       "      <td>396584.0</td>\n",
       "      <td>396070.0</td>\n",
       "      <td>400617.0</td>\n",
       "      <td>401848.0</td>\n",
       "      <td>406623.0</td>\n",
       "      <td>408441.0</td>\n",
       "      <td>408837.0</td>\n",
       "      <td>406441.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 359 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0           1           2           3    \\\n",
       "Date                1995-01-01  1995-02-01  1995-03-01  1995-04-01   \n",
       "City of london       91448.985   82202.773   79120.703   77101.208   \n",
       "Barking & dagenham   50460.227    51085.78    51268.97   53133.505   \n",
       "Barnet               93284.518    93190.17   92247.524   90762.875   \n",
       "Bexley                64958.09   64787.921   64367.493   64277.669   \n",
       "\n",
       "                           4           5           6           7    \\\n",
       "Date                1995-05-01  1995-06-01  1995-07-01  1995-08-01   \n",
       "City of london       84409.149   94900.512  110128.042  112329.438   \n",
       "Barking & dagenham   53042.249   53700.348   52113.122   52232.199   \n",
       "Barnet                 90258.0   90107.235   91441.248   92361.315   \n",
       "Bexley               63997.136   64252.323   63722.701     64432.6   \n",
       "\n",
       "                           8           9    ...         349         350  \\\n",
       "Date                1995-09-01  1995-10-01  ...  2024-02-01  2024-03-01   \n",
       "City of london       104473.11  108038.118  ...    840075.0    831249.0   \n",
       "Barking & dagenham   51471.614   51513.758  ...    328266.0    333303.0   \n",
       "Barnet               93273.122   92567.385  ...    563115.0    569976.0   \n",
       "Bexley               64509.548   64529.937  ...    394741.0    395633.0   \n",
       "\n",
       "                           351         352         353         354  \\\n",
       "Date                2024-04-01  2024-05-01  2024-06-01  2024-07-01   \n",
       "City of london        810250.0    813219.0    808227.0    754954.0   \n",
       "Barking & dagenham    335559.0    335794.0    332826.0    340826.0   \n",
       "Barnet                573051.0    580130.0    584621.0    590027.0   \n",
       "Bexley                396584.0    396070.0    400617.0    401848.0   \n",
       "\n",
       "                           355         356         357         358  \n",
       "Date                2024-08-01  2024-09-01  2024-10-01  2024-11-01  \n",
       "City of london        750362.0    719570.0    692265.0    670906.0  \n",
       "Barking & dagenham    338083.0    340295.0    340932.0    343528.0  \n",
       "Barnet                596078.0    592861.0    589938.0    592678.0  \n",
       "Bexley                406623.0    408441.0    408837.0    406441.0  \n",
       "\n",
       "[5 rows x 359 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prices formating to decimal float\n",
    "properties.iloc[1:] = properties.iloc[1:].apply(pd.to_numeric, errors='coerce').round(3)\n",
    "properties.style.format(precision=2)\n",
    "\n",
    "properties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knLUXHLypOtw"
   },
   "source": [
    "**2.5. Cleaning the data (part 3)**\n",
    "\n",
    "Do we have an equal number of observations in the ID, Average Price, Month, and London Borough columns? Remember that there are only 32 London Boroughs. How many entries do you have in that column? \n",
    "\n",
    "Check out the contents of the London Borough column, and if you find null values, get rid of them however you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BnvTW5a3p0fC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "354    0\n",
       "355    0\n",
       "356    0\n",
       "357    0\n",
       "358    0\n",
       "Length: 359, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop Null values \n",
    "properties.dropna(inplace = True)\n",
    "properties.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGEx6mJsp6dG"
   },
   "source": [
    "**2.6. Visualizing the data**\n",
    "\n",
    "To visualize the data, why not subset on a particular London Borough? Maybe do a line plot of Month against Average Price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'City of london', 'Barking & dagenham', 'Barnet', 'Bexley',\n",
       "       'Brent', 'Bromley', 'Camden', 'Croydon', 'Ealing', 'Enfield',\n",
       "       'Greenwich', 'Hackney', 'Hammersmith & fulham', 'Haringey', 'Harrow',\n",
       "       'Havering', 'Hillingdon', 'Hounslow', 'Islington',\n",
       "       'Kensington & chelsea', 'Kingston upon thames', 'Lambeth', 'Lewisham',\n",
       "       'Merton', 'Newham', 'Redbridge', 'Richmond upon thames', 'Southwark',\n",
       "       'Sutton', 'Tower hamlets', 'Waltham forest', 'Wandsworth',\n",
       "       'Westminster', 'Inner london', 'Outer london', 'North east',\n",
       "       'North west', 'Yorks & the humber', 'East midlands', 'West midlands',\n",
       "       'East of england', 'London', 'South east', 'South west', 'England'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAg5pT9cqHAR"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RangeIndex' object has no attribute 'year'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m borough_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBrent\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m london_borough \u001b[38;5;241m=\u001b[39m properties\u001b[38;5;241m.\u001b[39mloc[borough_name] \n\u001b[1;32m----> 7\u001b[0m properties\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m properties\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39myear \n\u001b[0;32m      8\u001b[0m properties_yearly \u001b[38;5;241m=\u001b[39m properties\u001b[38;5;241m.\u001b[39mgroupby(properties\u001b[38;5;241m.\u001b[39mcolumns, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m)) \n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RangeIndex' object has no attribute 'year'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot borought.  \n",
    "borough_name = \"Brent\"\n",
    "london_borough = properties.loc[borough_name] \n",
    "\n",
    "properties.columns = properties.columns.year \n",
    "properties_yearly = properties.groupby(properties.columns, axis=1).mean()\n",
    "\n",
    "plt.figure(figsize=(12, 6)) \n",
    "plt.plot(london_borough, linestyle='-', label=borough_name, color='r', linewidth=1)\n",
    "\n",
    "\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Average Price (£)\")\n",
    "plt.title(f\"Average House Price in {borough_name} Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aWTPqSJeqHnC"
   },
   "source": [
    "To limit the number of data points you have, you might want to extract the year from every month value your *Month* column. \n",
    "\n",
    "To this end, you *could* apply a ***lambda function***. Your logic could work as follows:\n",
    "1. look through the `Month` column\n",
    "2. extract the year from each individual value in that column \n",
    "3. store that corresponding year as separate column. \n",
    "\n",
    "Whether you go ahead with this is up to you. Just so long as you answer our initial brief: which boroughs of London have seen the greatest house price increase, on average, over the past two decades? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e0DF92cyqnu8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2knuTxAEqoJ4"
   },
   "source": [
    "**3. Modeling**\n",
    "\n",
    "Consider creating a function that will calculate a ratio of house prices, comparing the price of a house in 2018 to the price in 1998.\n",
    "\n",
    "Consider calling this function create_price_ratio.\n",
    "\n",
    "You'd want this function to:\n",
    "1. Take a filter of dfg, specifically where this filter constrains the London_Borough, as an argument. For example, one admissible argument should be: dfg[dfg['London_Borough']=='Camden'].\n",
    "2. Get the Average Price for that Borough, for the years 1998 and 2018.\n",
    "4. Calculate the ratio of the Average Price for 1998 divided by the Average Price for 2018.\n",
    "5. Return that ratio.\n",
    "\n",
    "Once you've written this function, you ultimately want to use it to iterate through all the unique London_Boroughs and work out the ratio capturing the difference of house prices between 1998 and 2018.\n",
    "\n",
    "Bear in mind: you don't have to write a function like this if you don't want to. If you can solve the brief otherwise, then great! \n",
    "\n",
    "***Hint***: This section should test the skills you acquired in:\n",
    "- Python Data Science Toolbox - Part One, all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKTyr437UgDa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzYUI7FxJpgv"
   },
   "source": [
    "### 4. Conclusion\n",
    "What can you conclude? Type out your conclusion below. \n",
    "\n",
    "Look back at your notebook. Think about how you might summarize what you have done, and prepare a quick presentation on it to your mentor at your next meeting. \n",
    "\n",
    "We hope you enjoyed this practical project. It should have consolidated your data hygiene and pandas skills by looking at a real-world problem involving just the kind of dataset you might encounter as a budding data scientist. Congratulations, and looking forward to seeing you at the next step in the course! "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Springboard Data Science Career Track Unit 4 Challenge - Tier 3 Complete .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
